{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 목적  \n",
    "실제 데이터(concrete 데이터셋)를 불러와 Surrogate Model에 gradient descent, GA를 구현하고 end-to-end로 문제없이 작동하는지 확인하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"vinayakshanawad/cement-manufacturing-concrete-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/ephemeral/home/.cache/kagglehub/datasets/vinayakshanawad/cement-manufacturing-concrete-dataset/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd\n",
    "df = pd.read_csv(path + \"/concrete.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 간단한 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Q1 = train['slag'].quantile(0.25)\n",
    "Q3 = train['slag'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f'Q1: {Q1}, Q3: {Q3}, IQR: {IQR}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(train['slag'], vert=False, patch_artist=True, showmeans=True, meanline=True)\n",
    "plt.xlabel('slag', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = test['slag'].quantile(0.25)\n",
    "Q3 = test['slag'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(f'Q1: {Q1}, Q3: {Q3}, IQR: {IQR}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(test['slag'], vert=False, patch_artist=True, showmeans=True, meanline=True)\n",
    "plt.xlabel('slag', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Model 학습 준비 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcreteDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, mean,std):\n",
    "        self.df = df\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx][['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']].to_numpy()\n",
    "        y = self.df.iloc[idx][['strength']].to_numpy()\n",
    "        x = torch.tensor(x, dtype=torch.float32)    \n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        x = (x - self.mean[:-1]) / self.std[:-1]\n",
    "        # y = (y - self.mean[7]) / self.std[7]\n",
    "        y = torch.log(y)\n",
    "        # if self.transform:\n",
    "        #     x = self.transform(x)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ConcreteDataset(df)\n",
    "\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age','strength']].to_numpy().mean(axis=0)\n",
    "std = train[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age','strength']].to_numpy().std(axis=0)\n",
    "mean = torch.tensor(mean, dtype=torch.float32)\n",
    "std = torch.tensor(std, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset_train = ConcreteDataset(train,mean,std)\n",
    "dataset_test = ConcreteDataset(test,mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_nn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_nn, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(8, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        xf = self.fc3(x)\n",
    "        return xf,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_nn()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "losses = []\n",
    "val_losses = []\n",
    "errors = []\n",
    "for i in range(200):\n",
    "    Lo = []\n",
    "    for inputs, outputs in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = outputs.cuda()\n",
    "        model.zero_grad()\n",
    "        pred,_ = model(inputs)\n",
    "        loss = torch.nn.MSELoss()(pred, outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Lo.append(loss.item())\n",
    "    \n",
    "    losses.append(np.mean(Lo))\n",
    "    err = []\n",
    "    vLo = []\n",
    "    for inputs, outputs in test_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = outputs.cuda()\n",
    "        pred,_ = model(inputs)\n",
    "        loss = torch.nn.MSELoss()(pred, outputs)\n",
    "        vLo.append(loss.item())\n",
    "        err.append(abs(torch.exp(pred.detach().cpu())- torch.exp(outputs.detach().cpu())).numpy())\n",
    "    errors.append(np.concatenate(err,axis=0).mean())\n",
    "    val_losses.append(np.mean(vLo))\n",
    "    print(f'losses: {np.mean(losses)}')\n",
    "    print(f'val_losses: {np.mean(val_losses)}')\n",
    "    print(f'errors: {np.concatenate(err,axis=0).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err = []\n",
    "mean_err = []\n",
    "pred_y = []\n",
    "\n",
    "for inputs, outputs in test_loader:\n",
    "    inputs = inputs.cuda()\n",
    "    outputs = outputs.cuda()\n",
    "    pred,_ = model(inputs)\n",
    "    loss = torch.nn.MSELoss()(pred, outputs)\n",
    "    val_losses.append(loss.item())\n",
    "    pred_y.append(torch.exp(pred.detach().cpu()).numpy())\n",
    "    y_p = (torch.exp(pred.detach().cpu())- torch.exp(outputs.detach().cpu()))**2\n",
    "    y_t = (mean[-1].repeat(outputs.shape[0]).reshape(outputs.shape[0],1) - torch.exp(outputs.detach().cpu()))**2\n",
    "    err.append(y_p.numpy())\n",
    "    mean_err.append(y_t.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.concatenate(err,axis=0)\n",
    "mean_err = np.concatenate(mean_err,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = np.concatenate(pred_y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err.shape)\n",
    "print(mean_err.shape)\n",
    "print(pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1- np.mean(err)/np.mean(mean_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1030\n",
    "p = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1- (np.mean(err)/(n-p-1))/(np.mean(mean_err)/(n-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err[np.where(err < 100)[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err[np.where(err < 300)[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - 시도 1 : Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "save_SSE = []\n",
    "save_SST = []\n",
    "patience = 10\n",
    "lr_decay_factor = 0.5  \n",
    "for x,y in tqdm(test_loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    # print(x.shape)\n",
    "    # brewa\n",
    "    y_opt = y.detach()\n",
    "    init_x = torch.randn(x.shape[0],x.shape[1], device='cuda', requires_grad=True) # .requires_grad_(True).cuda()\n",
    "    # init_x = mean[:-1].expand(10,8).clone().requires_grad_(True)\n",
    "    init_x.requires_grad = True\n",
    "    optimizer = optim.Adam([init_x], lr=0.1)\n",
    "    \n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    min_val = 1e6\n",
    "    min_yp = None\n",
    "    min_yt = None\n",
    "\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for i in range(10000):\n",
    "        optimizer.zero_grad()\n",
    "        # with torch.no_grad():\n",
    "        pred,features = model(init_x)\n",
    "        loss = torch.nn.MSELoss()(pred, y_opt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss.item() < min_val:\n",
    "            min_val = loss.item()\n",
    "            min_yp = (init_x.detach().cpu()*std[:-1] - x.detach().cpu()*std[:-1])**2\n",
    "            min_yt = (mean[:-1].repeat(init_x.shape[0]).reshape(init_x.shape[0],-1) - x.detach().cpu()*std[:-1])**2\n",
    "            # print(init_x.detach().cpu()*std[:-1].mean())\n",
    "            # print(\"??\")\n",
    "            # print((x.detach().cpu()*std[:-1])[0])\n",
    "            # print((mean[:-1].repeat(init_x.shape[0]).reshape(init_x.shape[0],-1))[0])\n",
    "            # print((init_x.detach().cpu()*std[:-1])[0])\n",
    "            # break\n",
    "            # print(min_x.mean())\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        \n",
    "        if no_improve_epochs > patience:\n",
    "            optimizer.param_groups[0]['lr'] *= lr_decay_factor\n",
    "            # print(f'lr decayed to {optimizer.param_groups[0][\"lr\"]}')\n",
    "            no_improve_epochs = 0\n",
    "        # print((init_x.detach().cpu() - x.cpu()).numpy().mean())\n",
    "    \n",
    "    save_SSE.append(min_yp.numpy())\n",
    "    save_SST.append(min_yt.numpy())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE = np.concatenate(save_SSE,axis=0)\n",
    "save_SST = np.concatenate(save_SST,axis=0)\n",
    "print(save_SSE.shape)\n",
    "print(save_SST.shape)\n",
    "print(1- np.mean(save_SSE)/np.mean(save_SST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std# np.concatenate(save1,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SST.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (save_SSE.mean(axis=0) / save_SST.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - 시도 2 : GA(deap 라이브러리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = test.iloc[:,-1]\n",
    "print(y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gt_y in y_target:\n",
    "    print(type(gt_y)) # str\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적합도 함수\n",
    "def fitness(individual):\n",
    "    \"\"\"\n",
    "    individual : population의 한 개체\n",
    "    \"\"\"\n",
    "    x_tensor = torch.tensor(individual, dtype=torch.float32).unsqueeze(0).to('cuda') # 배치차원추가\n",
    "    with torch.no_grad():\n",
    "        y_pred, _ = model(x_tensor)\n",
    "    fit_fun = -abs(y_pred - y_target)\n",
    "    return fit_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('attr_float', random.uniform, x_min, x_max)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_float, n=1)\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register('evaluate', fitness)\n",
    "toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "toolbox.register('mate', tools.cxBlend, alpha=0.5)\n",
    "toolbox.register('mutate', tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 50\n",
    "population = toolbox.population(n=pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(population[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(population[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = []\n",
    "for idx, ind in enumerate(population):\n",
    "    if idx < 2:\n",
    "        print(len(ind))\n",
    "        # print(toolbox.evaluate(ind))\n",
    "        # print(toolbox.evaluate(ind)[0])\n",
    "        alist.append(toolbox.evaluate(ind)[0])\n",
    "        \n",
    "print(alist)\n",
    "print(alist[0])\n",
    "print(alist[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in population:\n",
    "    if hasattr(ind, 'fitness'):\n",
    "        print('true')\n",
    "    else:\n",
    "        print('false')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_scores = [toolbox.evaluate(ind)[0] for ind in population]\n",
    "for ind, fit in zip(population, fitness_scores):\n",
    "    # ind.fitness.values = (fit,)\n",
    "    # print(fit.item())\n",
    "    print((fit,))\n",
    "    print(ind.fitness)\n",
    "    # print(ind.fitness.values)\n",
    "    # ind.fitness = fit.item()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = toolbox.select(population, len(population) // 2)\n",
    "print(len(parents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = tools.selBest(parents, k=len(population))\n",
    "# print(offspring)\n",
    "print(len(offspring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = list(map(toolbox.clone, offspring))\n",
    "# print(offspring)\n",
    "print(len(offspring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(offspring), 2):\n",
    "    if random.random() < 0.7:\n",
    "        print(toolbox.mate(offspring[i-1], offspring[i]))\n",
    "        print(len(toolbox.mate(offspring[i-1], offspring[i])))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(offspring)\n",
    "print(len(offspring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in offspring:\n",
    "    if random.random() < 0.2:\n",
    "        print(toolbox.mutate(child))\n",
    "        print(len(toolbox.mutate(child)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in offspring:\n",
    "    print(ind)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_,y_ in dataset_train:\n",
    "    print(x_)\n",
    "    print(y_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_except_strength = train.drop(columns='strength')\n",
    "train_except_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y target 뺀 train array\n",
    "train_array = np.array(train_except_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train array 열 별 sum\n",
    "x_sum = np.sum(train_array, axis=0)\n",
    "x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = train_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_sum / train_len\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = np.std(train_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train_array = (train_array - x_mean) / x_std\n",
    "normalize_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.min(normalize_train_array, axis=0)  # 열별 최소값\n",
    "x_max = np.max(normalize_train_array, axis=0)  # 열별 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_min)\n",
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_normalize_mean = normalize_train_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from deap import base, creator, tools\n",
    "\n",
    "SSE_element = []\n",
    "SST_element = []\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    row = np.array(row)\n",
    "    gt_y = row[-1]\n",
    "    gt_x = row[:-1]\n",
    "    gt_x = (gt_x - x_mean) / x_std\n",
    "    gt_y = np.log(gt_y)\n",
    "\n",
    "    def fitness(individual):\n",
    "        x_tensor = torch.tensor(individual, dtype=torch.float32).unsqueeze(0).to('cuda') # 배치차원추가\n",
    "        with torch.no_grad():\n",
    "            y_pred, _ = model(x_tensor)\n",
    "        # fit_fun = -abs(y_pred - gt_y)\n",
    "        fit_fun = -(y_pred - gt_y)**2\n",
    "        return fit_fun\n",
    "\n",
    "    creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "    creator.create('Individual', list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register('attr_float', random.uniform, x_min, x_max)\n",
    "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_float, n=1)\n",
    "    toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register('evaluate', fitness)\n",
    "    # toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "    toolbox.register('select', tools.selBest, k=5) # Rank Selection\n",
    "    toolbox.register('mate', tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register('mutate', tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "\n",
    "    pop_size = 50\n",
    "    population = toolbox.population(n=pop_size)\n",
    "\n",
    "    for gen in range(100):\n",
    "\n",
    "        fitness_scores = [toolbox.evaluate(ind)[0] for ind in population]\n",
    "        for ind, fit in zip(population, fitness_scores):\n",
    "            ind.fitness.values = (fit,)\n",
    "            # ind.fitness = fit.item()\n",
    "\n",
    "        # offspring 생성\n",
    "        if len(population) == 1:\n",
    "            break\n",
    "        # parents = toolbox.select(population, len(population) // 2)\n",
    "        parents = toolbox.select(population) # Rank Selection\n",
    "        # print('population : ', len(population))\n",
    "        # print('parents : ', len(parent\n",
    "        # s))\n",
    "        offspring = tools.selBest(parents, k=len(population))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        # print('offspring : ', len(offspring))\n",
    "\n",
    "        # crossover\n",
    "        for i in range(1, len(offspring), 2):\n",
    "            if random.random() < 0.7:\n",
    "                toolbox.mate(offspring[i-1], offspring[i])\n",
    "                # print('cross over : ', len(toolbox.mate(offspring[i-1], offspring[i])))\n",
    "        # print('offspring의 길이 - crossover 후' , len(offspring))\n",
    "\n",
    "        # mutation\n",
    "        for child in offspring:\n",
    "            if random.random() < 0.2:\n",
    "                toolbox.mutate(child)\n",
    "                # print('child : ', len(toolbox.mutate(child)))\n",
    "\n",
    "        # print('offspring의 길이 -  mutation 후' , len(offspring))\n",
    "\n",
    "        # 새로운 자식만 평가\n",
    "        for ind in offspring:\n",
    "            del ind.fitness.values\n",
    "\n",
    "        # 다음 세대 개체로 갱신\n",
    "        population[:] = offspring\n",
    "        \n",
    "        # print(len(population))\n",
    "        \n",
    "    best_individual = tools.selBest(population, k=1)[0]\n",
    "    # print(\"Best Individual:\", best_individual)\n",
    "    best_individual = best_individual[0]\n",
    "        \n",
    "    gt_x = np.array([gt_x])\n",
    "    x_pred = np.array(best_individual)\n",
    "\n",
    "    # print(gt_x.shape)\n",
    "    # print(x_pred.shape)\n",
    "    x_pred = x_pred.reshape(1,8)\n",
    "    # print(x_pred.shape)\n",
    "    # print(x_mean.shape)\n",
    "\n",
    "    # print('gt_x : ', gt_x)\n",
    "    # print('x_pred : ', x_pred)\n",
    "    \n",
    "    # print('sum_gt_x : ', np.sum(gt_x))\n",
    "    # x_mean = np.sum(gt_x)/len(test_len)\n",
    "    # print('x_mean : ', x_mean)\n",
    "\n",
    "    # x_bar = []\n",
    "    # for _ in range(len(gt_x[0])):\n",
    "    #     x_bar.append(x_mean)\n",
    "    # x_bar = np.array(x_mean)\n",
    "    # print('x_bar : ', x_bar)\n",
    "\n",
    "    for num in (gt_x - x_pred):\n",
    "        SSE_element.append(num**2)\n",
    "    # print('sse_element : ', SSE_element)\n",
    "\n",
    "    for num in (gt_x - train_x_normalize_mean.reshape(1,8)):\n",
    "        SST_element.append(num**2)\n",
    "    \n",
    "    # print(gt_x.shape)\n",
    "    # print(train_x_normalize_mean.shape)\n",
    "    # print(x_pred.shape)\n",
    "    # break \n",
    "    # print('sst_element : ', SST_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SSE_element))\n",
    "print(len(SST_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = np.sum(SSE_element, axis=0)\n",
    "SST = np.sum(SST_element, axis=0)\n",
    "print(SSE, SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SSE_element[0].shape)\n",
    "print(SST_element[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = 1 - (SSE/SST)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - 시도 3 : GA(pygmo 라이브러리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmo as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sphere:\n",
    "    def __init__(self, model, target, x_min, x_max):\n",
    "        self.model = model\n",
    "        self.target = target\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "\n",
    "    def fitness(self, x):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(x_tensor)\n",
    "        \n",
    "        if isinstance(y_pred, tuple):\n",
    "            y_pred = y_pred[0]\n",
    "        \n",
    "        fit_fun = -((y_pred.item() - self.target) ** 2)\n",
    "        return [fit_fun]\n",
    "\n",
    "    def get_bounds(self):\n",
    "        # return ([-5] * 8, [5] * 8)  # 탐색 범위 설정 (8차원 예시)\n",
    "        return (self.x_min.tolist(), self.x_max.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "results = []\n",
    "for gt_y in tqdm(y_target):\n",
    "\n",
    "    prob = pg.problem(Sphere(model, gt_y, x_min, x_max))\n",
    "    algo = pg.algorithm(pg.gaco(gen=100, ker=50, q=1.0, oracle=0.0, acc=0.01, threshold=1, memory=False))\n",
    "    pop = pg.population(prob, size=50)\n",
    "    pop = algo.evolve(pop)\n",
    "    results.append((pop.champion_x, pop.champion_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solution = min(results, key=lambda x: x[1])\n",
    "print(\"Best solution (x):\", best_solution[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pygmo as pg\n",
    "from tqdm import tqdm\n",
    "\n",
    "SSE_element = []\n",
    "SST_element = []\n",
    "\n",
    "class SphereProblem:\n",
    "    def __init__(self, model, gt_y, x_min, x_max):\n",
    "        self.model = model\n",
    "        self.gt_y = gt_y\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "\n",
    "    def fitness(self, x):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to('cuda')  # 배치 차원 추가\n",
    "        with torch.no_grad():\n",
    "            y_pred, _ = self.model(x_tensor)\n",
    "    \n",
    "        fit_fun = -((y_pred.item() - self.gt_y) ** 2)\n",
    "        return [fit_fun]\n",
    "\n",
    "    def get_bounds(self):\n",
    "        return (self.x_min.tolist(), self.x_max.tolist())\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    row = np.array(row)\n",
    "    gt_y = row[-1]\n",
    "    gt_x = row[:-1]\n",
    "    gt_x = (gt_x - x_mean) / x_std\n",
    "    gt_y = np.log(gt_y)\n",
    "\n",
    "    # x_min = np.min(test.iloc[:, :-1].values, axis=0)\n",
    "    # x_max = np.max(test.iloc[:, :-1].values, axis=0)\n",
    "    x_min = np.min(normalize_train_array, axis=0)\n",
    "    x_max = np.max(normalize_train_array, axis=0)\n",
    "\n",
    "    prob = pg.problem(SphereProblem(model, gt_y, x_min, x_max))\n",
    "\n",
    "    algo = pg.algorithm(pg.sga(gen=100, cr=0.7, eta_c=1.0, m=0.2, param_m=1.0))\n",
    "\n",
    "    pop = pg.population(prob, size=50)\n",
    "    pop = algo.evolve(pop)\n",
    "\n",
    "    best_individual = pop.champion_x\n",
    "\n",
    "    gt_x = np.array([gt_x])\n",
    "    x_pred = np.array(best_individual)\n",
    "    # print(gt_x.shape)\n",
    "    # print(x_pred.shape)\n",
    "    x_pred = x_pred.reshape(1,8)\n",
    "    # print(x_pred.shape)\n",
    "    # print(x_mean.shape)\n",
    "    for num in (gt_x - x_pred):\n",
    "        SSE_element.append(num ** 2)\n",
    "\n",
    "    for num in (gt_x - train_x_normalize_mean.reshape(1,8)):\n",
    "        SST_element.append(num ** 2)\n",
    "\n",
    "print('SSE:', np.sum(SSE_element))\n",
    "print('SST:', np.sum(SST_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SSE_element))\n",
    "print(len(SST_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SSE_element[0].shape)\n",
    "print(SST_element[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = np.sum(SSE_element, axis=0)\n",
    "SST = np.sum(SST_element, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = 1 - (SSE/SST)\n",
    "print(r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Model - 시도 4 : GA(pygad 라이브러리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pygad\n",
    "\n",
    "SSE_element = []\n",
    "SST_element = []\n",
    "\n",
    "\n",
    "def fitness_function(ga_instance, solution, solution_idx):\n",
    "    x_tensor = torch.tensor(solution, dtype=torch.float32).unsqueeze(0).to('cuda')  # 배치 차원 추가\n",
    "    with torch.no_grad():\n",
    "        y_pred, _ = model(x_tensor)\n",
    "\n",
    "    fit_fun = -((y_pred.item() - ga_instance.gt_y) ** 2)\n",
    "    return fit_fun\n",
    "\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "    row = np.array(row)\n",
    "    gt_y = row[-1]\n",
    "    gt_x = row[:-1]\n",
    "    gt_x = (gt_x - x_mean) / x_std\n",
    "    gt_y = np.log(gt_y)\n",
    "\n",
    "    # x_min = np.min(train.iloc[:, :-1].values, axis=0)\n",
    "    # x_max = np.max(train.iloc[:, :-1].values, axis=0)\n",
    "    x_min = np.min(normalize_train_array, axis=0)\n",
    "    x_max = np.max(normalize_train_array, axis=0)\n",
    "\n",
    "\n",
    "    num_generations = 100\n",
    "    num_parents_mating = 10\n",
    "    sol_per_pop = 50\n",
    "    num_genes = len(gt_x)\n",
    "\n",
    "    initial_population = np.random.uniform(low=x_min, high=x_max, size=(sol_per_pop, num_genes))\n",
    "\n",
    "    ga_instance = pygad.GA(\n",
    "        num_generations=num_generations,\n",
    "        num_parents_mating=num_parents_mating,\n",
    "        fitness_func=fitness_function,\n",
    "        sol_per_pop=sol_per_pop,\n",
    "        num_genes=num_genes,\n",
    "        init_range_low=x_min,\n",
    "        init_range_high=x_max,\n",
    "        mutation_percent_genes=20,\n",
    "        parent_selection_type=\"rank\",\n",
    "        crossover_type=\"single_point\",\n",
    "        mutation_type=\"random\"\n",
    "    )\n",
    "\n",
    "    ga_instance.gt_y = gt_y\n",
    "\n",
    "    ga_instance.run()\n",
    "\n",
    "    best_solution, best_solution_fitness, _ = ga_instance.best_solution()\n",
    "\n",
    "    x_pred = np.array(best_solution).reshape(1, -1)\n",
    "    # print(x_pred.shape)\n",
    "    gt_x = np.array([gt_x])\n",
    "    # print(gt_x.shape)\n",
    "\n",
    "    for num in (gt_x - x_pred):\n",
    "        SSE_element.append(num ** 2)\n",
    "\n",
    "    x_mean = np.mean(gt_x)\n",
    "    for num in (gt_x - train_x_normalize_mean.reshape(1,8)):\n",
    "        SST_element.append(num ** 2)\n",
    "    \n",
    "\n",
    "print('SSE:', np.sum(SSE_element))\n",
    "print('SST:', np.sum(SST_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SSE_element))\n",
    "print(len(SST_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SSE_element[0].shape)\n",
    "print(SST_element[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = np.sum(SSE_element, axis=0)\n",
    "SST = np.sum(SST_element, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = 1 - (SSE/SST)\n",
    "print(r_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
