{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 목적  \n",
    "Surrogate 모델에 GA(유전 알고리즘)을 적용하기 전에, 실제 데이터를 불러와 input과 output을 확인하면서 end-to-end 학습이 정상적으로 이루어지는지 검증하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd\n",
    "df = pd.read_csv('../data/concrete_processed.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'strength'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target, test_size=0.2, random_state=42):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Model(simpleNN)과 Surrogate Model(GA - deap라이브러리) 연결 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SimpleNN_dataloader(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,X,y):\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor([self.y[idx]], dtype=torch.float32)\n",
    "        # y = torch.log(y)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "def simpleNN_load_data(X_train,X_test,y_train,y_test):\n",
    "\n",
    "    train_data = SimpleNN_dataloader(X_train,y_train)\n",
    "    test_data = SimpleNN_dataloader(X_test,y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=10, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = simpleNN_load_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "class simpleNN_model(torch.nn.Module):\n",
    "    def __init__(self,input_size,output_size=1):\n",
    "        super(simpleNN_model,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size,16)\n",
    "        self.fc2 = torch.nn.Linear(16,32)\n",
    "        self.fc3 = torch.nn.Linear(32,output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def to(self, *args, **kwargs):\n",
    "        super().to(*args, **kwargs)\n",
    "        self.device = next(self.parameters()).device  # device 속성 자동 설정\n",
    "        return self\n",
    "\n",
    "\n",
    "def simpleNN_train(train_loader,val_loader):\n",
    "\n",
    "    model = simpleNN_model(input_size=train_loader.dataset.X.shape[1])\n",
    "    model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs:=200):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        for data,target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(model.device)\n",
    "            target = target.to(model.device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "            for data,target in val_loader:\n",
    "                data = data.to(model.device)\n",
    "                target = target.to(model.device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "                val_loss += loss.item()\n",
    "            print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleNN_predict(model,X_test):\n",
    "    model.eval()\n",
    "    if isinstance(X_test, torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            X_test = X_test.to(model.device)\n",
    "            output = model(X_test)\n",
    "        # return output.numpy()\n",
    "        return output.cpu().numpy()  # GPU에서 CPU로 복사 후 numpy로 변환\n",
    "    elif isinstance(X_test, torch.utils.data.DataLoader):\n",
    "        y_pred = []\n",
    "        for data,target in X_test:\n",
    "            with torch.no_grad():\n",
    "                data = data.to(model.device)\n",
    "                output = model(data)\n",
    "                output = output.detach().cpu().numpy()\n",
    "                # target = target.numpy()\n",
    "                y_pred.append(output)\n",
    "        y_pred = np.concatenate(y_pred, axis=0).squeeze()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleNN_model = simpleNN_train(train_loader=train_loader, val_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sum = np.sum(X_train, axis=0)\n",
    "x_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_sum / train_len\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.min(X_train, axis=0)\n",
    "x_max = np.max(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_min)\n",
    "print(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from deap import base, creator, tools\n",
    "\n",
    "\n",
    "def ga_deap_search(model, pred_func, X_train, X_test, y_test):\n",
    "    test = X_test\n",
    "    gt_ys = y_test\n",
    "\n",
    "    x_min = np.min(X_train, axis=0)\n",
    "    x_max = np.max(X_train, axis=0) \n",
    "    \n",
    "    res = []\n",
    "    for gt_y in tqdm(gt_ys):\n",
    "\n",
    "        def fitness(population):\n",
    "            # x_tensor = torch.tensor(individual, dtype=torch.float32).unsqueeze(0).to('cuda') # 배치차원추가\n",
    "            x_tensors = torch.tensor(population, dtype=torch.float32).reshape(-1, 8).to('cuda')\n",
    "\n",
    "            print('x_tensors shape : ', x_tensors.shape)\n",
    "            print('x_tensors type : ', type(x_tensors))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_pred = pred_func(model=simpleNN_model, X_test=x_tensors)\n",
    "                y_pred_tensor = torch.tensor(y_pred, dtype=torch.float32)\n",
    "            \n",
    "            print('y pred shape : ', y_pred_tensor.shape)\n",
    "            print('y pred type : ', type(y_pred_tensor))\n",
    "            \n",
    "            fit_fun = -(y_pred_tensor - gt_y)**2\n",
    "            return fit_fun\n",
    "\n",
    "        creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "        creator.create('Individual', list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "        toolbox.register('attr_float', random.uniform, x_min, x_max)\n",
    "        toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_float, n=1)\n",
    "        toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        \n",
    "        toolbox.register('evaluate', fitness)\n",
    "        # toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "        toolbox.register('select', tools.selBest, k=5) # Rank Selection\n",
    "        toolbox.register('mate', tools.cxBlend, alpha=0.5)\n",
    "        toolbox.register('mutate', tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "\n",
    "        pop_size = 50\n",
    "        # pop_size = len(test)\n",
    "        population = toolbox.population(n=pop_size)\n",
    "        print('population type', type(population))\n",
    "        for gen in range(100):\n",
    "\n",
    "            # fitness_scores = [toolbox.evaluate(ind)[0] for ind in population]\n",
    "            fitness_scores = toolbox.evaluate(population)\n",
    "            for ind, fit in zip(population, fitness_scores):\n",
    "                ind.fitness.values = (fit,)\n",
    "\n",
    "            # offspring 생성\n",
    "            if len(population) == 1:\n",
    "                break\n",
    "            parents = toolbox.select(population, k=len(population)) # Rank Selection\n",
    "            offspring = tools.selBest(parents, k=len(population))\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # crossover\n",
    "            for i in range(1, len(offspring), 2):\n",
    "                if random.random() < 0.7:\n",
    "                    toolbox.mate(offspring[i-1], offspring[i])\n",
    "\n",
    "            # mutation\n",
    "            for child in offspring:\n",
    "                if random.random() < 0.2:\n",
    "                    toolbox.mutate(child)\n",
    "\n",
    "            # 새로운 자식만 평가\n",
    "            for ind in offspring:\n",
    "                del ind.fitness.values\n",
    "\n",
    "            # 다음 세대 개체로 갱신\n",
    "            population[:] = offspring\n",
    "        \n",
    "        best_individual = tools.selBest(population, k=1)[0]\n",
    "        best_individual = best_individual[0]\n",
    "            \n",
    "        x_pred = np.array(best_individual)\n",
    "\n",
    "        x_pred = x_pred.reshape(1,8)\n",
    "        res.append(x_pred)\n",
    "        break\n",
    "    \n",
    "    return np.concatenate(res, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ga_deap_search(simpleNN_model, simpleNN_predict, X_train, X_test, y_test)\n",
    "\n",
    "\"\"\"\n",
    "x_tensors shape :  torch.Size([50, 8])\n",
    "x_tensors type :  <class 'torch.Tensor'>\n",
    "y pred shape :  torch.Size([50, 1])\n",
    "y pred type :  <class 'torch.Tensor'>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Model(simpleNN)과 Surrogate Model(GA - pygmo라이브러리) 연결 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pygmo as pg\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def ga_pygmo_search(model, pred_func, X_train, X_test, y_test):\n",
    "\n",
    "    test = X_test\n",
    "    gt_ys = y_test\n",
    "\n",
    "    x_min = np.min(X_train, axis=0)\n",
    "    x_max = np.max(X_train, axis=0)\n",
    "\n",
    "    class SphereProblem:\n",
    "        def __init__(self, model, gt_y, x_min, x_max):\n",
    "            self.model = model\n",
    "            self.gt_y = gt_y\n",
    "            self.x_min = x_min\n",
    "            self.x_max = x_max\n",
    "\n",
    "        def fitness(self, x):\n",
    "            x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to('cuda')  # 배치 차원 추가\n",
    "\n",
    "            # print('x_tensor shape : ', x_tensor.shape)\n",
    "            # print('x_tensor type : ', type(x_tensor))\n",
    "            with torch.no_grad():\n",
    "                y_pred = model(x_tensor)\n",
    "                y_pred_tensor = torch.tensor(y_pred, dtype=torch.float32)\n",
    "            # print('y pred shape : ', y_pred_tensor.shape)\n",
    "            # print('y pred type : ', type(y_pred_tensor))\n",
    "            fit_fun = -((y_pred_tensor.item() - self.gt_y) ** 2)\n",
    "            return [fit_fun]\n",
    "            \n",
    "\n",
    "        def get_bounds(self):\n",
    "            return (self.x_min.tolist(), self.x_max.tolist()) \n",
    "        \n",
    "    def batch_evaluate_population(model, pop, gt_y, pred_func):\n",
    "        \n",
    "        x_tensors = torch.tensor(pop.get_x(), dtype=torch.float32).reshape(-1, 8).to('cuda')\n",
    "        print('batch x_tensors shape : ', x_tensors.shape)\n",
    "        print('batch x_tensors type : ', type(x_tensors))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = pred_func(model=simpleNN_model, X_test=x_tensors)\n",
    "            y_pred_tensor = torch.tensor(y_preds, dtype=torch.float32)\n",
    "        \n",
    "        print('batch y_pred_tensor shape : ', y_pred_tensor.shape)\n",
    "        print('batch y_pred_tensor type : ', type(y_pred_tensor))\n",
    "\n",
    "        fitness_values = -((y_pred_tensor - gt_y) ** 2).cpu().numpy()\n",
    "        \n",
    "        # for idx, fit_val in enumerate(fitness_values):\n",
    "        #     pop.set_f(idx, [fit_val])\n",
    "        \n",
    "        # return pop\n",
    "        new_pop = pg.population(pop.problem)\n",
    "        for i, fit_val in enumerate(fitness_values):\n",
    "            # # 기존 개체를 그대로 추가하면서 fitness 값만 업데이트\n",
    "            # individual = pop.get_x()[i].flatten() if len(pop.get_x()[i].shape) > 1 else pop.get_x()[i]\n",
    "            # print(f\"Shape of individual before push_back: {individual.shape}\")\n",
    "            individual = np.array(pop.get_x()[i]).flatten()\n",
    "            fit_val = float(fit_val)\n",
    "            new_pop.push_back(individual, [fit_val])\n",
    "    \n",
    "        return new_pop\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "\n",
    "    for gt_y in tqdm(gt_ys):\n",
    "\n",
    "        prob = pg.problem(SphereProblem(simpleNN_model, gt_y, x_min, x_max))\n",
    "\n",
    "        algo = pg.algorithm(pg.sga(gen=100, cr=0.7, eta_c=1.0, m=0.2, param_m=1.0))\n",
    "\n",
    "        pop = pg.population(prob, size=50)\n",
    "\n",
    "        # 배치 평가 호출\n",
    "        pop = batch_evaluate_population(simpleNN_model, pop, gt_y, pred_func)\n",
    "        \n",
    "        # pop = algo.evolve(pop)\n",
    "\n",
    "        best_individual = pop.champion_x\n",
    "\n",
    "        x_pred = np.array(best_individual)\n",
    "        x_pred = x_pred.reshape(1,8)\n",
    "        res.append(x_pred)\n",
    "        break\n",
    "\n",
    "    return np.concatenate(res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ga_pygmo_search(simpleNN_model, simpleNN_predict, X_train, X_test, y_test)\n",
    "\"\"\"\n",
    "batch x_tensors shape :  torch.Size([50, 8])\n",
    "batch x_tensors type :  <class 'torch.Tensor'>\n",
    "batch y_pred_tensor shape :  torch.Size([50, 1])\n",
    "batch y_pred_tensor type :  <class 'torch.Tensor'>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Model(LightGBM)과 Surrogate Model(GA - deap라이브러리) 연결 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "def lightgbm_train(train_data, val_data, params = None):\n",
    "\n",
    "    if params is None:\n",
    "        params = {\n",
    "            \"objective\": \"regression\",        # 회귀 문제\n",
    "            \"metric\": \"rmse\",                 # 평가 지표\n",
    "            \"boosting_type\": \"gbdt\",          # 부스팅 방식\n",
    "            \"learning_rate\": 0.05,            # 학습 속도\n",
    "            \"num_leaves\": 31,                 # 리프 노드 개수\n",
    "            \"feature_fraction\": 0.8,          # 피처 샘플링 비율\n",
    "            \"bagging_fraction\": 0.8,          # 데이터 샘플링 비율\n",
    "            \"bagging_freq\": 5,                # 샘플링 빈도\n",
    "            \"min_data_in_leaf\": 20,           # 리프 노드 최소 데이터 수\n",
    "            \"verbosity\": -1                   # 출력 최소화\n",
    "        }\n",
    "\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.log_evaluation(period=100),  # 100번마다 로그 출력\n",
    "            lgb.early_stopping(stopping_rounds=50)  # 조기 종료 설정\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def lightgbm_evaluate(model, train_data, val_data):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    # X_train = train_data.get_data()\n",
    "    # print(train_data)\n",
    "    y_train = train_data.get_label()\n",
    "    X_test = val_data.get_data()\n",
    "    y_test = val_data.get_label()\n",
    "\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    \n",
    "    \n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    SSE = np.sum(np.square(y_test - y_pred))    \n",
    "    SST = np.sum(np.square(y_test - y_train.mean()))\n",
    "    r2 = 1 - SSE/SST\n",
    "\n",
    "    rmse = np.sqrt(np.mean(np.square(y_test - y_pred)))\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "\n",
    "def lightgbm_predict(model, X_test):\n",
    "    # Tensor를 numpy 배열로 변환\n",
    "    X_test = X_test.detach().cpu().numpy()\n",
    "    \n",
    "    # X_test = X_test.get_data()\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def lightgbm_load_data(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=False)\n",
    "    val_data = lgb.Dataset(X_test, label=y_test, reference=train_data,free_raw_data=False)\n",
    " \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = lightgbm_load_data(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model = lightgbm_train(train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from deap import base, creator, tools\n",
    "\n",
    "\n",
    "def ga_deap_search(model, pred_func, X_train, X_test, y_test):\n",
    "    test = X_test\n",
    "    gt_ys = y_test\n",
    "\n",
    "    x_min = np.min(X_train, axis=0)\n",
    "    x_max = np.max(X_train, axis=0) \n",
    "    \n",
    "    res = []\n",
    "    for gt_y in tqdm(gt_ys):\n",
    "\n",
    "        def fitness(population):\n",
    "            # x_tensor = torch.tensor(individual, dtype=torch.float32).unsqueeze(0).to('cuda') # 배치차원추가\n",
    "            x_tensors = torch.tensor(population, dtype=torch.float32).reshape(-1, 8).to('cuda')\n",
    "\n",
    "            print('x_tensors shape : ', x_tensors.shape)\n",
    "            print('x_tensors type : ', type(x_tensors))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_pred = pred_func(model=lightgbm_model, X_test=x_tensors)\n",
    "                y_pred_tensor = torch.tensor(y_pred, dtype=torch.float32)\n",
    "            \n",
    "            print('y_pred_tensor shape : ', y_pred_tensor.shape)\n",
    "            print('y_pred_tensor type : ', type(y_pred_tensor))\n",
    "            \n",
    "            fit_fun = -(y_pred_tensor - gt_y)**2\n",
    "            return fit_fun\n",
    "\n",
    "        creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
    "        creator.create('Individual', list, fitness=creator.FitnessMax)\n",
    "\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "        toolbox.register('attr_float', random.uniform, x_min, x_max)\n",
    "        toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_float, n=1)\n",
    "        toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        \n",
    "        toolbox.register('evaluate', fitness)\n",
    "        # toolbox.register('select', tools.selTournament, tournsize=3)\n",
    "        toolbox.register('select', tools.selBest, k=5) # Rank Selection\n",
    "        toolbox.register('mate', tools.cxBlend, alpha=0.5)\n",
    "        toolbox.register('mutate', tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "\n",
    "        pop_size = 50\n",
    "        # pop_size = len(test)\n",
    "        population = toolbox.population(n=pop_size)\n",
    "        print('population type', type(population))\n",
    "        for gen in range(100):\n",
    "\n",
    "            # fitness_scores = [toolbox.evaluate(ind)[0] for ind in population]\n",
    "            fitness_scores = toolbox.evaluate(population)\n",
    "            for ind, fit in zip(population, fitness_scores):\n",
    "                ind.fitness.values = (fit,)\n",
    "\n",
    "            # offspring 생성\n",
    "            if len(population) == 1:\n",
    "                break\n",
    "            parents = toolbox.select(population, k=len(population)) # Rank Selection\n",
    "            offspring = tools.selBest(parents, k=len(population))\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # crossover\n",
    "            for i in range(1, len(offspring), 2):\n",
    "                if random.random() < 0.7:\n",
    "                    toolbox.mate(offspring[i-1], offspring[i])\n",
    "\n",
    "            # mutation\n",
    "            for child in offspring:\n",
    "                if random.random() < 0.2:\n",
    "                    toolbox.mutate(child)\n",
    "\n",
    "            # 새로운 자식만 평가\n",
    "            for ind in offspring:\n",
    "                del ind.fitness.values\n",
    "\n",
    "            # 다음 세대 개체로 갱신\n",
    "            population[:] = offspring\n",
    "        \n",
    "        best_individual = tools.selBest(population, k=1)[0]\n",
    "        best_individual = best_individual[0]\n",
    "            \n",
    "        x_pred = np.array(best_individual)\n",
    "\n",
    "        x_pred = x_pred.reshape(1,8)\n",
    "        res.append(x_pred)\n",
    "        break\n",
    "    \n",
    "    return np.concatenate(res, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ga_deap_search(lightgbm_model, lightgbm_predict, X_train, X_test, y_test)\n",
    "\"\"\"\n",
    "x_tensors shape :  torch.Size([50, 8])\n",
    "x_tensors type :  <class 'torch.Tensor'>\n",
    "y pred shape :  torch.Size([50])\n",
    "y pred type :  <class 'torch.Tensor'>\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
