{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"vinayakshanawad/cement-manufacturing-concrete-dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/ephemeral/home/.cache/kagglehub/datasets/vinayakshanawad/cement-manufacturing-concrete-dataset/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fireducks.pandas as pd\n",
    "df = pd.read_csv(path + \"/concrete.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = sklearn.model_selection.train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcreteDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, mean,std):\n",
    "        self.df = df\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx][['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']].to_numpy()\n",
    "        y = self.df.iloc[idx][['strength']].to_numpy()\n",
    "        x = torch.tensor(x, dtype=torch.float32)    \n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        x = (x - self.mean[:-1]) / self.std[:-1]\n",
    "        # y = (y - self.mean[7]) / self.std[7]\n",
    "        y = torch.log(y)\n",
    "        # if self.transform:\n",
    "        #     x = self.transform(x)\n",
    "            \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ConcreteDataset(df)\n",
    "\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age','strength']].to_numpy().mean(axis=0)\n",
    "std = train[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age','strength']].to_numpy().std(axis=0)\n",
    "mean = torch.tensor(mean, dtype=torch.float32)\n",
    "std = torch.tensor(std, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.transforms as transforms\n",
    "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset_train = ConcreteDataset(train,mean,std)\n",
    "dataset_test = ConcreteDataset(test,mean,std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(dataset_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_nn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_nn, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(8, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, 32)\n",
    "        self.fc3 = torch.nn.Linear(32, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        xf = self.fc3(x)\n",
    "        return xf,x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_nn()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "losses = []\n",
    "val_losses = []\n",
    "errors = []\n",
    "for i in range(200):\n",
    "    Lo = []\n",
    "    for inputs, outputs in train_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = outputs.cuda()\n",
    "        model.zero_grad()\n",
    "        pred,_ = model(inputs)\n",
    "        loss = torch.nn.MSELoss()(pred, outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        Lo.append(loss.item())\n",
    "    \n",
    "    losses.append(np.mean(Lo))\n",
    "    err = []\n",
    "    vLo = []\n",
    "    for inputs, outputs in test_loader:\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = outputs.cuda()\n",
    "        pred,_ = model(inputs)\n",
    "        loss = torch.nn.MSELoss()(pred, outputs)\n",
    "        vLo.append(loss.item())\n",
    "        err.append(abs(torch.exp(pred.detach().cpu())- torch.exp(outputs.detach().cpu())).numpy())\n",
    "    errors.append(np.concatenate(err,axis=0).mean())\n",
    "    val_losses.append(np.mean(vLo))\n",
    "    print(f'losses: {np.mean(losses)}')\n",
    "    print(f'val_losses: {np.mean(val_losses)}')\n",
    "    print(f'errors: {np.concatenate(err,axis=0).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate(errors,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(errors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(errors))\n",
    "plt.plot(len(errors)*[np.mean(df['strength'].to_numpy())])\n",
    "plt.plot(len(errors)*[np.mean(df['strength'].to_numpy())+np.std(df['strength'].to_numpy())])\n",
    "plt.plot(len(errors)*[np.mean(df['strength'].to_numpy())-np.std(df['strength'].to_numpy())])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(pred_y, residuals, alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "err = []\n",
    "mean_err = []\n",
    "pred_y = []\n",
    "\n",
    "for inputs, outputs in test_loader:\n",
    "    inputs = inputs.cuda()\n",
    "    outputs = outputs.cuda()\n",
    "    pred,_ = model(inputs)\n",
    "    loss = torch.nn.MSELoss()(pred, outputs)\n",
    "    val_losses.append(loss.item())\n",
    "    pred_y.append(torch.exp(pred.detach().cpu()).numpy())\n",
    "    y_p = (torch.exp(pred.detach().cpu())- torch.exp(outputs.detach().cpu()))**2\n",
    "    y_t = (mean[-1].repeat(outputs.shape[0]).reshape(outputs.shape[0],1) - torch.exp(outputs.detach().cpu()))**2\n",
    "    err.append(y_p.numpy())\n",
    "    mean_err.append(y_t.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.concatenate(err,axis=0)\n",
    "mean_err = np.concatenate(mean_err,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = np.concatenate(pred_y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(err.shape)\n",
    "print(mean_err.shape)\n",
    "print(pred_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1- np.mean(err)/np.mean(mean_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1030\n",
    "p = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1- (np.mean(err)/(n-p-1))/(np.mean(mean_err)/(n-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err[np.where(err < 100)[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err[np.where(err < 300)[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred_y,err, alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_const = sm.add_constant(test[['cement','slag','ash','water','superplastic','coarseagg','fineagg','age']].to_numpy())  # 상수항 추가\n",
    "bp_test = het_breuschpagan(err.flatten(), X_with_const)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Breusch-Pagan Test Results:\")\n",
    "print(f\"Lagrange Multiplier Statistic: {bp_test[0]}\")\n",
    "print(f\"p-value: {bp_test[1]}\")\n",
    "print(f\"F-statistic: {bp_test[2]}\")\n",
    "print(f\"F-statistic p-value: {bp_test[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bp_test[1] < 0.05:\n",
    "    print(\"The assumption of homoscedasticity is violated.\")\n",
    "else:\n",
    "    print(\"The assumption of homoscedasticity is satisfied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['strength'].to_numpy()\n",
    "plt.hist(df['strength'].to_numpy(),bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for inputs, outputs in test_loader:\n",
    "    inputs = inputs.cuda()\n",
    "    outputs = outputs.cuda()\n",
    "    pred,features = model(inputs)\n",
    "    features = features.detach().cpu().numpy()\n",
    "    feature_list.extend(features)\n",
    "feature_list = np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit_transform(feature_list)\n",
    "plt.scatter(tsne.embedding_[:, 0], tsne.embedding_[:, 1], c=test['strength'].to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for inputs, outputs in train_loader:\n",
    "    inputs = inputs.cuda()\n",
    "    outputs = outputs.cuda()\n",
    "    pred,features = model(inputs)\n",
    "    features = features.detach().cpu().numpy()\n",
    "    feature_list.extend(features)\n",
    "feature_list = np.array(feature_list)\n",
    "tsne.fit_transform(feature_list)\n",
    "plt.scatter(tsne.embedding_[:, 0], tsne.embedding_[:, 1], c=train['strength'].to_numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = 0\n",
    "save_SSE = []\n",
    "save_SST = []\n",
    "patience = 10\n",
    "lr_decay_factor = 0.5  \n",
    "for x,y in tqdm.tqdm(test_loader):\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    # print(x.shape)\n",
    "    # brewa\n",
    "    y_opt = y.detach()\n",
    "    init_x = torch.randn(x.shape[0],x.shape[1], device='cuda', requires_grad=True) # .requires_grad_(True).cuda()\n",
    "    # init_x = mean[:-1].expand(10,8).clone().requires_grad_(True)\n",
    "    init_x.requires_grad = True\n",
    "    optimizer = optim.Adam([init_x], lr=0.1)\n",
    "    \n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    min_val = 1e6\n",
    "    min_yp = None\n",
    "    min_yt = None\n",
    "\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for i in range(10000):\n",
    "        optimizer.zero_grad()\n",
    "        # with torch.no_grad():\n",
    "        pred,features = model(init_x)\n",
    "        loss = torch.nn.MSELoss()(pred, y_opt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss.item() < min_val:\n",
    "            min_val = loss.item()\n",
    "            min_yp = (init_x.detach().cpu()*std[:-1] - x.detach().cpu()*std[:-1])**2\n",
    "            min_yt = (mean[:-1].repeat(init_x.shape[0]).reshape(init_x.shape[0],-1) - x.detach().cpu()*std[:-1])**2\n",
    "        \n",
    "            # print(min_x.mean())\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        \n",
    "        if no_improve_epochs > patience:\n",
    "            optimizer.param_groups[0]['lr'] *= lr_decay_factor\n",
    "            # print(f'lr decayed to {optimizer.param_groups[0][\"lr\"]}')\n",
    "            no_improve_epochs = 0\n",
    "        # print((init_x.detach().cpu() - x.cpu()).numpy().mean())\n",
    "    \n",
    "    save_SSE.append(min_yp.numpy())\n",
    "    save_SST.append(min_yt.numpy())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE = np.concatenate(save_SSE,axis=0)\n",
    "save_SST = np.concatenate(save_SST,axis=0)\n",
    "print(save_SSE.shape)\n",
    "print(save_SST.shape)\n",
    "print(1- np.mean(save_SSE)/np.mean(save_SST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save = torch.tensor(np.array(save))*std[7] + mean[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std# np.concatenate(save1,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SSE.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_SST.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_SSE.mean(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (save_SSE.mean(axis=0) / save_SST.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(save_SSE.mean(axis=0) / save_SST.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(save1.mean(axis=1),bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
